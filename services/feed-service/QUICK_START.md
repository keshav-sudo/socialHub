# ğŸš€ Feed Service - Quick Start Guide

## âœ¨ Features at a Glance

âœ… **Real-time feed** via Kafka events
âœ… **Redis caching** for fast retrieval
âœ… **Auto-regeneration** if cache deleted
âœ… **Scalable** architecture
âœ… **Production ready** with Docker

---

## ğŸ¯ Main Question: Redis Delete Hone Par Feed Kaise Milega?

### Answer: **Auto-Regeneration (Lazy Loading)** â­

```
User â†’ Request Feed â†’ Redis Check â†’ Cache MISS! 
  â†’ Auto-fetch from Post DB 
  â†’ Rebuild in Redis 
  â†’ Return to User
```

**User Impact:** Small delay (50-200ms) on first request. Then instant!
**Data Loss:** ZERO (Post DB is source of truth)

---

## ğŸƒ Quick Start

### 1. Start Services
```bash
# Start all services
docker-compose up -d

# Or just feed service
docker-compose up feed-service
```

### 2. Test Auto-Regeneration
```bash
# Step 1: Clear Redis (simulate cache loss)
docker exec -it redis redis-cli FLUSHALL

# Step 2: Request feed (will auto-regenerate)
curl http://localhost:8080/feed/user123

# Response will include "regenerated: true"
```

### 3. Cache Following List (Important!)
```bash
# Feed regeneration needs following list
curl -X POST http://localhost:8080/feed/cache-following \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "user123",
    "followingIds": ["user456", "user789"]
  }'
```

---

## ğŸ“¡ API Endpoints

### Get Feed (Auto-regenerates if empty)
```bash
curl http://localhost:8080/feed/user123?page=1&limit=20
```

### Manual Regenerate
```bash
curl -X POST http://localhost:8080/feed/regenerate/user123 \
  -H "Content-Type: application/json" \
  -d '{"followingIds": ["user456", "user789"]}'
```

### Add Post (Kafka will do this automatically)
```bash
curl -X POST http://localhost:8080/feed/post \
  -H "Content-Type: application/json" \
  -d '{
    "authorId": "user456",
    "postId": "post123",
    "username": "john"
  }'
```

---

## ğŸ”§ Environment Variables

```env
PORT=5005
REDIS_HOST=redis
REDIS_PORT=6379
KAFKA_BROKER=kafka:9092
KAFKA_CLIENT_ID=feed-service
KAFKA_GROUP_ID=feed-service-group
```

---

## ğŸ“Š How It Works

### Normal Flow (Cache Hit)
```
1. Post created in Post Service
2. Kafka event emitted
3. Feed Service consumes event
4. Adds to all follower feeds in Redis
5. User requests feed â†’ Instant from Redis
```

### Recovery Flow (Cache Miss)
```
1. User requests feed
2. Redis cache is empty
3. System fetches following list
4. Queries Post DB for recent posts
5. Rebuilds feed in Redis
6. Returns feed to user
7. Next request is instant!
```

---

## âš¡ Performance

| Scenario | Time |
|----------|------|
| Feed from cache | 5-20ms |
| Feed regeneration | 50-200ms |
| Subsequent requests | 5-20ms |

---

## ğŸ› Troubleshooting

### "Empty feed returned"
**Solution:** Cache following list first
```bash
POST /feed/cache-following
Body: { userId, followingIds }
```

### "Kafka consumer not working"
**Check:** Kafka is running
```bash
docker-compose ps kafka
```

### "Redis connection failed"
**Check:** Redis is running
```bash
docker-compose ps redis
```

---

## ğŸ“ Important Files

- `README.md` - Complete documentation
- `IMPLEMENTATION_SUMMARY.md` - Detailed implementation info
- `src/services/FeedRegenerationService.ts` - Regeneration logic
- `src/services/FeedService.ts` - Core feed logic

---

## ğŸ¯ Key Points

1. âœ… Redis delete = **No problem** (auto-regenerates)
2. âœ… Data source = **Post Database** (not Redis)
3. âœ… Cache = **Speed optimization** only
4. âœ… Zero manual intervention needed
5. âœ… Production ready

---

**Questions? Check `README.md` for full documentation!**
